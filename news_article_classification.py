# -*- coding: utf-8 -*-
"""News_article_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k5Bq5lymb_mt9H2b9ew_HaOnhemyZ5-o
"""

# Step 1: Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re
import string

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

nltk.download('stopwords')
nltk.download('wordnet')

# Load dataset
df = pd.read_csv('/content/data_news.csv')

# Show first few rows
df.head()

# Combine text fields (headline + short_description + keywords)
df['text'] = df['headline'].fillna('') + ' ' + df['short_description'].fillna('') + ' ' + df['keywords'].fillna('')

# Drop unused columns
df = df[['category', 'text']]

# Drop missing or empty values
df.dropna(inplace=True)
df = df[df['text'].str.strip() != '']

# Text Cleaning Function
def clean_text(text):
    text = text.lower()
    text = re.sub(r'\[.*?\]', '', text)
    text = re.sub(r'https?://\S+|www\.\S+', '', text)
    text = re.sub(r'<.*?>+', '', text)
    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub(r'\n', ' ', text)
    text = re.sub(r'\w*\d\w*', '', text)
    return text

# Apply cleaning
df['clean_text'] = df['text'].apply(clean_text)

# Stopwords and Lemmatization
stop = stopwords.words('english')
lemmatizer = WordNetLemmatizer()

def preprocess(text):
    words = text.split()
    words = [lemmatizer.lemmatize(word) for word in words if word not in stop]
    return ' '.join(words)

df['processed_text'] = df['clean_text'].apply(preprocess)

# TF-IDF Vectorization
tfidf = TfidfVectorizer(max_features=5000)
X = tfidf.fit_transform(df['processed_text'])

# Target
y = df['category']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Models
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Naive Bayes": MultinomialNB(),
    "SVM": LinearSVC()
}

# Training and Evaluation
for name, model in models.items():
    print(f"\n{name}")
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    print("Accuracy:", accuracy_score(y_test, preds))
    print("Classification Report:\n", classification_report(y_test, preds))

# Save trained models
trained_models = {
    "Logistic Regression": models["Logistic Regression"],
    "Naive Bayes": models["Naive Bayes"],
    "SVM": models["SVM"]
}

# Prediction Function
def predict_category(user_input, chosen_model):
    # Clean and preprocess input
    cleaned = clean_text(user_input)
    processed = preprocess(cleaned)

    # Transform with TF-IDF
    vectorized = tfidf.transform([processed])

    # Predict
    model = trained_models.get(chosen_model)
    if model:
        prediction = model.predict(vectorized)
        print(f"\nPredicted Category: {prediction[0]}")
    else:
        print("Invalid model choice.")

# Single input from user
print("\nEnter a news article to classify:")
user_text = input("Enter text (headline/description/keywords): ")

print("\nChoose a model for prediction:")
print("1. Logistic Regression")
print("2. Naive Bayes")
print("3. SVM")

choice = input("Enter 1, 2, or 3: ")

model_map = {
    "1": "Logistic Regression",
    "2": "Naive Bayes",
    "3": "SVM"
}

selected_model = model_map.get(choice)

if selected_model:
    predict_category(user_text, selected_model)
else:
    print("Invalid model selection.")

